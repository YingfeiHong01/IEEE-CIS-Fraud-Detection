{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random, datetime, math\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False\n",
    "MAKE_MODEL_TEST = False\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_normalization(dt_df, periods, columns):\n",
    "    for period in periods:\n",
    "        for col in columns:\n",
    "            new_col = col +'_'+ period\n",
    "            dt_df[col] = dt_df[col].astype(float)  \n",
    "\n",
    "            temp_min = dt_df.groupby([period])[col].agg(['min']).reset_index()\n",
    "            temp_min.index = temp_min[period].values\n",
    "            temp_min = temp_min['min'].to_dict()\n",
    "\n",
    "            temp_max = dt_df.groupby([period])[col].agg(['max']).reset_index()\n",
    "            temp_max.index = temp_max[period].values\n",
    "            temp_max = temp_max['max'].to_dict()\n",
    "\n",
    "            temp_mean = dt_df.groupby([period])[col].agg(['mean']).reset_index()\n",
    "            temp_mean.index = temp_mean[period].values\n",
    "            temp_mean = temp_mean['mean'].to_dict()\n",
    "\n",
    "            temp_std = dt_df.groupby([period])[col].agg(['std']).reset_index()\n",
    "            temp_std.index = temp_std[period].values\n",
    "            temp_std = temp_std['std'].to_dict()\n",
    "\n",
    "            dt_df['temp_min'] = dt_df[period].map(temp_min)\n",
    "            dt_df['temp_max'] = dt_df[period].map(temp_max)\n",
    "            dt_df['temp_mean'] = dt_df[period].map(temp_mean)\n",
    "            dt_df['temp_std'] = dt_df[period].map(temp_std)\n",
    "\n",
    "            dt_df[new_col+'_min_max'] = (dt_df[col]-dt_df['temp_min'])/(dt_df['temp_max']-dt_df['temp_min'])\n",
    "            dt_df[new_col+'_std_score'] = (dt_df[col]-dt_df['temp_mean'])/(dt_df['temp_std'])\n",
    "            del dt_df['temp_min'],dt_df['temp_max'],dt_df['temp_mean'],dt_df['temp_std']\n",
    "    return dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(train_df, test_df, columns, self_encoding=False):\n",
    "    for col in columns:\n",
    "        temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "        fq_encode = temp_df[col].value_counts(dropna=False).to_dict()\n",
    "        if self_encoding:\n",
    "            train_df[col] = train_df[col].map(fq_encode)\n",
    "            test_df[col]  = test_df[col].map(fq_encode)            \n",
    "        else:\n",
    "            train_df[col+'_fq_enc'] = train_df[col].map(fq_encode)\n",
    "            test_df[col+'_fq_enc']  = test_df[col].map(fq_encode)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeblock_frequency_encoding(train_df, test_df, periods, columns, \n",
    "                                 with_proportions=True, only_proportions=False):\n",
    "    for period in periods:\n",
    "        for col in columns:\n",
    "            new_col = col +'_'+ period\n",
    "            train_df[new_col] = train_df[col].astype(str)+'_'+train_df[period].astype(str)\n",
    "            test_df[new_col]  = test_df[col].astype(str)+'_'+test_df[period].astype(str)\n",
    "\n",
    "            temp_df = pd.concat([train_df[[new_col]], test_df[[new_col]]])\n",
    "            fq_encode = temp_df[new_col].value_counts().to_dict()\n",
    "\n",
    "            train_df[new_col] = train_df[new_col].map(fq_encode)\n",
    "            test_df[new_col]  = test_df[new_col].map(fq_encode)\n",
    "            \n",
    "            if only_proportions:\n",
    "                train_df[new_col] = train_df[new_col]/train_df[period+'_total']\n",
    "                test_df[new_col]  = test_df[new_col]/test_df[period+'_total']\n",
    "\n",
    "            if with_proportions:\n",
    "                train_df[new_col+'_proportions'] = train_df[new_col]/train_df[period+'_total']\n",
    "                test_df[new_col+'_proportions']  = test_df[new_col]/test_df[period+'_total']\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uid_aggregation(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "def uid_aggregation_and_normalization(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            \n",
    "            new_norm_col_name = col+'_'+main_column+'_std_norm'\n",
    "            norm_cols = []\n",
    "            \n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "                norm_cols.append(new_col_name)\n",
    "            \n",
    "            train_df[new_norm_col_name] = (train_df[main_column]-train_df[norm_cols[0]])/train_df[norm_cols[1]]\n",
    "            test_df[new_norm_col_name]  = (test_df[main_column]-test_df[norm_cols[0]])/test_df[norm_cols[1]]          \n",
    "            \n",
    "            del train_df[norm_cols[0]], train_df[norm_cols[1]]\n",
    "            del test_df[norm_cols[0]], test_df[norm_cols[1]]\n",
    "                                              \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cor_and_remove(train_df, test_df, i_cols, new_columns, remove=False):\n",
    "    # Check correllation\n",
    "    print('Correlations','#'*10)\n",
    "    for col in new_columns:\n",
    "        cor_cof = np.corrcoef(train_df[TARGET], train_df[col].fillna(0))[0][1]\n",
    "        print(col, cor_cof)\n",
    "\n",
    "    if remove:\n",
    "        print('#'*10)\n",
    "        print('Best options:')\n",
    "        best_fe_columns = []\n",
    "        for main_col in i_cols:\n",
    "            best_option = ''\n",
    "            best_cof = 0\n",
    "            for col in new_columns:\n",
    "                if main_col in col:\n",
    "                    cor_cof = np.corrcoef(train_df[TARGET], train_df[col].fillna(0))[0][1]\n",
    "                    cor_cof = (cor_cof**2)**0.5\n",
    "                    if cor_cof>best_cof:\n",
    "                        best_cof = cor_cof\n",
    "                        best_option = col\n",
    "\n",
    "            print(main_col, best_option, best_cof)            \n",
    "            best_fe_columns.append(best_option)\n",
    "\n",
    "        for col in new_columns:\n",
    "            if col not in best_fe_columns:\n",
    "                del train_df[col], test_df[col]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "('Shape control:', (590540, 394), (506691, 394))\n"
     ]
    }
   ],
   "source": [
    "print('Load Data')\n",
    "train_df = pd.read_pickle('train_transaction.pkl')\n",
    "\n",
    "if LOCAL_TEST:\n",
    "    \n",
    "    # Convert TransactionDT to \"Month\" time-period. \n",
    "    # We will also drop penultimate block \n",
    "    # to \"simulate\" test set values difference\n",
    "    train_df['DT_M'] = train_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    train_df['DT_M'] = (train_df['DT_M'].dt.year-2017)*12 + train_df['DT_M'].dt.month \n",
    "    test_df = train_df[train_df['DT_M']==train_df['DT_M'].max()].reset_index(drop=True)\n",
    "    train_df = train_df[train_df['DT_M']<(train_df['DT_M'].max()-1)].reset_index(drop=True)\n",
    "    \n",
    "    train_identity = pd.read_pickle('train_identity.pkl')\n",
    "    test_identity  = train_identity[train_identity['TransactionID'].isin(\n",
    "                                    test_df['TransactionID'])].reset_index(drop=True)\n",
    "    train_identity = train_identity[train_identity['TransactionID'].isin(\n",
    "                                    train_df['TransactionID'])].reset_index(drop=True)\n",
    "    del train_df['DT_M'], test_df['DT_M']\n",
    "    \n",
    "else:\n",
    "    test_df = pd.read_pickle('test_transaction.pkl')\n",
    "    train_identity = pd.read_pickle('train_identity.pkl')\n",
    "    test_identity = pd.read_pickle('test_identity.pkl')\n",
    "    \n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### All features columns\n",
    "#################################################################################\n",
    "## Main Data\n",
    "# 'TransactionID',                     -> This is pure noise, we cannot use this column as feature\n",
    "# 'isFraud',                           -> Our Target\n",
    "# 'TransactionDT',                     -> Time from reference time point. VERY valuable column\n",
    "# 'TransactionAmt',                    -> Many unique values and has to be combined with other columns\n",
    "#                                         The best score boost should come from \n",
    "#                                         TransactionDT->TransactionAmt combination\n",
    "# 'ProductCD',                         -> 100% categorical feature options to use:\n",
    "#                                         Frequency encoding/Target encoding/\n",
    "#                                         Combinations with other columns/Model categorical feature\n",
    "# 'card1' - 'card6',                   -> Categorical features with information about Client\n",
    "# 'addr1' - 'addr2',                   -> add2 - Country / addr1 - subzone\n",
    "# 'dist1' - 'dist2',                   -> dist2 - Country distance / dist1 - local distance from merchant\n",
    "# 'P_emaildomain' - 'R_emaildomain',   -> Categorical feature. It's possible to make \n",
    "#                                         subgroup feature from it or general group\n",
    "# 'C1' - 'C14'                         -> Counts. Should be numerical features (all ints?)\n",
    "# 'D1' - 'D15'                         -> Timedeltas - minimal value will be same for each month and day\n",
    "#                                         but maximum and mean values will grow over time \n",
    "# 'M1' - 'M9'\n",
    "# 'V1' - 'V339'\n",
    "\n",
    "## Identity Data\n",
    "# 'TransactionID'\n",
    "# 'id_01' - 'id_38'\n",
    "# 'DeviceType',\n",
    "# 'DeviceInfo'\n",
    "\n",
    "# Add list of feature that we will\n",
    "# remove later from final features list\n",
    "remove_features = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,\n",
    "    ]\n",
    "\n",
    "base_columns = [col for col in list(train_df) if col not in remove_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TransactionDT\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "dates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n",
    "\n",
    "# Let's add temporary \"time variables\" for aggregations\n",
    "# and add normal \"time variables\"\n",
    "for df in [train_df, test_df]:\n",
    "    \n",
    "    # Temporary variables for aggregation\n",
    "    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    df['DT_M'] = ((df['DT'].dt.year-2017)*12 + df['DT'].dt.month).astype(np.int8)\n",
    "    df['DT_W'] = ((df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear).astype(np.int8)\n",
    "    df['DT_D'] = ((df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear).astype(np.int16)\n",
    "    \n",
    "    df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n",
    "    df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n",
    "    df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n",
    "        \n",
    "    # Possible solo feature\n",
    "    df['is_december'] = df['DT'].dt.month\n",
    "    df['is_december'] = (df['is_december']==12).astype(np.int8)\n",
    "\n",
    "    # Holidays\n",
    "    df['is_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "\n",
    "# Remove temporary features from final list\n",
    "remove_features += ['DT','DT_M','DT_W','DT_D','DT_hour','DT_day_week','DT_day_month']\n",
    "    \n",
    "# Total transactions per timeblock\n",
    "for col in ['DT_M','DT_W','DT_D']:\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()\n",
    "            \n",
    "    train_df[col+'_total'] = train_df[col].map(fq_encode)\n",
    "    test_df[col+'_total']  = test_df[col].map(fq_encode)\n",
    "    \n",
    "    # We can't use it as solo feature\n",
    "    remove_features.append(col+'_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rare cards', 5993)\n",
      "('No intersection in Train', 10396)\n",
      "('Intersection in Train', 580144)\n",
      "####################\n",
      "('No intersection in Train', 'card2', 5012)\n",
      "('Intersection in Train', 'card2', 585528)\n",
      "####################\n",
      "('No intersection in Train', 'card3', 47)\n",
      "('Intersection in Train', 'card3', 590493)\n",
      "####################\n",
      "('No intersection in Train', 'card4', 0)\n",
      "('Intersection in Train', 'card4', 590540)\n",
      "####################\n",
      "('No intersection in Train', 'card5', 7279)\n",
      "('Intersection in Train', 'card5', 583261)\n",
      "####################\n",
      "('No intersection in Train', 'card6', 30)\n",
      "('Intersection in Train', 'card6', 590510)\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "########################### Card columns \"outliers\"\n",
    "for col in ['card1']: \n",
    "    valid_card = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    valid_card = valid_card[col].value_counts()\n",
    "    valid_card_std = valid_card.values.std()\n",
    "\n",
    "    invalid_cards = valid_card[valid_card<=2]\n",
    "    print('Rare cards',len(invalid_cards))\n",
    "\n",
    "    valid_card = valid_card[valid_card>2]\n",
    "    valid_card = list(valid_card.index)\n",
    "\n",
    "    print('No intersection in Train', len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "\n",
    "    train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)\n",
    "    print('#'*20)\n",
    "\n",
    "for col in ['card2','card3','card4','card5','card6',]: \n",
    "    print('No intersection in Train', col, len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', col, len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "    print('#'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Most common uIds:\n",
      "('##########', 'uid')\n",
      "7919.0_194.0     14891\n",
      "9500.0_321.0     14112\n",
      "15885.0_545.0    10332\n",
      "17188.0_321.0    10312\n",
      "15066.0_170.0     7918\n",
      "12695.0_490.0     7079\n",
      "6019.0_583.0      6766\n",
      "12544.0_321.0     6760\n",
      "2803.0_100.0      6126\n",
      "7585.0_553.0      5325\n",
      "Name: uid, dtype: int64\n",
      "('##########', 'uid2')\n",
      "9500.0_321.0_150.0_226.0     14112\n",
      "15885.0_545.0_185.0_138.0    10332\n",
      "17188.0_321.0_150.0_226.0    10312\n",
      "7919.0_194.0_150.0_166.0      8844\n",
      "15066.0_170.0_150.0_102.0     7918\n",
      "12695.0_490.0_150.0_226.0     7079\n",
      "6019.0_583.0_150.0_226.0      6766\n",
      "12544.0_321.0_150.0_226.0     6760\n",
      "2803.0_100.0_150.0_226.0      6126\n",
      "7919.0_194.0_150.0_nan        6047\n",
      "Name: uid2, dtype: int64\n",
      "('##########', 'uid3')\n",
      "15885.0_545.0_185.0_138.0_nan_nan       9900\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0    5862\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0    5766\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0     4647\n",
      "3154.0_408.0_185.0_224.0_nan_nan        4398\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0    3538\n",
      "16132.0_111.0_150.0_226.0_299.0_87.0    3523\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0    3419\n",
      "9500.0_321.0_150.0_226.0_272.0_87.0     2715\n",
      "5812.0_408.0_185.0_224.0_nan_nan        2639\n",
      "Name: uid3, dtype: int64\n",
      "('##########', 'uid4')\n",
      "15885.0_545.0_185.0_138.0_nan_nan_hotmail.com     4002\n",
      "15885.0_545.0_185.0_138.0_nan_nan_gmail.com       3830\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_gmail.com    2235\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0_gmail.com    2045\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0_gmail.com     1947\n",
      "3154.0_408.0_185.0_224.0_nan_nan_hotmail.com      1890\n",
      "3154.0_408.0_185.0_224.0_nan_nan_gmail.com        1537\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0_gmail.com    1473\n",
      "15775.0_481.0_150.0_102.0_330.0_87.0_nan          1453\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0_gmail.com    1383\n",
      "Name: uid4, dtype: int64\n",
      "('##########', 'uid5')\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0_nan         5446\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_nan         5322\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0_nan          4403\n",
      "15885.0_545.0_185.0_138.0_nan_nan_hotmail.com    4002\n",
      "15885.0_545.0_185.0_138.0_nan_nan_gmail.com      3830\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0_nan         3365\n",
      "16132.0_111.0_150.0_226.0_299.0_87.0_nan         3212\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0_nan         3027\n",
      "9500.0_321.0_150.0_226.0_272.0_87.0_nan          2601\n",
      "7664.0_490.0_150.0_226.0_264.0_87.0_nan          2396\n",
      "Name: uid5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################### Client Virtual ID\n",
    "# Let's add some kind of client uID based on cardID and addr columns\n",
    "# The value will be very specific for each client so we need to remove it\n",
    "# from final features. But we can use it for aggregations.\n",
    "train_df['uid'] = train_df['card1'].astype(str)+'_'+train_df['card2'].astype(str)\n",
    "test_df['uid'] = test_df['card1'].astype(str)+'_'+test_df['card2'].astype(str)\n",
    "\n",
    "train_df['uid2'] = train_df['uid'].astype(str)+'_'+train_df['card3'].astype(str)+'_'+train_df['card5'].astype(str)\n",
    "test_df['uid2'] = test_df['uid'].astype(str)+'_'+test_df['card3'].astype(str)+'_'+test_df['card5'].astype(str)\n",
    "\n",
    "train_df['uid3'] = train_df['uid2'].astype(str)+'_'+train_df['addr1'].astype(str)+'_'+train_df['addr2'].astype(str)\n",
    "test_df['uid3'] = test_df['uid2'].astype(str)+'_'+test_df['addr1'].astype(str)+'_'+test_df['addr2'].astype(str)\n",
    "\n",
    "train_df['uid4'] = train_df['uid3'].astype(str)+'_'+train_df['P_emaildomain'].astype(str)\n",
    "test_df['uid4'] = test_df['uid3'].astype(str)+'_'+test_df['P_emaildomain'].astype(str)\n",
    "\n",
    "train_df['uid5'] = train_df['uid3'].astype(str)+'_'+train_df['R_emaildomain'].astype(str)\n",
    "test_df['uid5'] = test_df['uid3'].astype(str)+'_'+test_df['R_emaildomain'].astype(str)\n",
    "\n",
    "# Add values remove list\n",
    "new_columns = ['uid','uid2','uid3','uid4','uid5']\n",
    "remove_features += new_columns\n",
    "\n",
    "print('#'*10)\n",
    "print('Most common uIds:')\n",
    "for col in new_columns:\n",
    "    print('#'*10, col)\n",
    "    print(train_df[col].value_counts()[:10])\n",
    "\n",
    "# Do Global frequency encoding \n",
    "i_cols = ['card1','card2','card3','card5'] + new_columns\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### card3/card5 most common hour \n",
    "# card3 or card5 is a bank country?\n",
    "# can we find:\n",
    "# - the most popular Transaction Hour\n",
    "# - the most popular Week Day\n",
    "# and then find distance from it\n",
    "\n",
    "# Prepare bank type feature\n",
    "for df in [train_df, test_df]:\n",
    "    df['bank_type'] = df['card3'].astype(str) +'_'+ df['card5'].astype(str)\n",
    "remove_features.append('bank_type') \n",
    "\n",
    "encoding_mean = {\n",
    "    1: ['DT_D','DT_hour','_hour_dist','DT_hour_mean'],\n",
    "    2: ['DT_W','DT_day_week','_week_day_dist','DT_day_week_mean'],\n",
    "    3: ['DT_M','DT_day_month','_month_day_dist','DT_day_month_mean'],\n",
    "    }\n",
    "\n",
    "encoding_best = {\n",
    "    1: ['DT_D','DT_hour','_hour_dist_best','DT_hour_best'],\n",
    "    2: ['DT_W','DT_day_week','_week_day_dist_best','DT_day_week_best'],\n",
    "    3: ['DT_M','DT_day_month','_month_day_dist_best','DT_day_month_best'],   \n",
    "    }\n",
    "\n",
    "# Some ugly code here (even worse than in other parts)\n",
    "for col in ['card3','card5','bank_type']:\n",
    "    for df in [train_df, test_df]:\n",
    "        for encode in encoding_mean:\n",
    "            encode = np.array(encoding_mean[encode]).copy()\n",
    "            new_col = col + '_' + encode[0] + encode[2]\n",
    "            df[new_col] = df[col].astype(str) +'_'+ df[encode[0]].astype(str)\n",
    "\n",
    "            temp_dict = df.groupby([new_col])[encode[1]].agg(['mean']).reset_index().rename(\n",
    "                                                                    columns={'mean': encode[3]})\n",
    "            temp_dict.index = temp_dict[new_col].values\n",
    "            temp_dict = temp_dict[encode[3]].to_dict()\n",
    "            df[new_col] = df[encode[1]] - df[new_col].map(temp_dict)\n",
    "\n",
    "        for encode in encoding_best:\n",
    "            encode = np.array(encoding_best[encode]).copy()\n",
    "            new_col = col + '_' + encode[0] + encode[2]\n",
    "            df[new_col] = df[col].astype(str) +'_'+ df[encode[0]].astype(str)\n",
    "            temp_dict = df.groupby([col,encode[0],encode[1]])[encode[1]].agg(['count']).reset_index().rename(\n",
    "                                                                    columns={'count': encode[3]})\n",
    "\n",
    "            temp_dict.sort_values(by=[col,encode[0],encode[3]], inplace=True)\n",
    "            temp_dict = temp_dict.drop_duplicates(subset=[col,encode[0]], keep='last')\n",
    "            temp_dict[new_col] = temp_dict[col].astype(str) +'_'+ temp_dict[encode[0]].astype(str)\n",
    "            temp_dict.index = temp_dict[new_col].values\n",
    "            temp_dict = temp_dict[encode[1]].to_dict()\n",
    "            df[new_col] = df[encode[1]] - df[new_col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### bank_type\n",
    "# Tracking nomal activity\n",
    "# by doing timeblock frequency encoding\n",
    "i_cols = ['bank_type'] #['uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "periods = ['DT_M','DT_W','DT_D']\n",
    "\n",
    "# We have few options to encode it here:\n",
    "# - Just count transactions\n",
    "# (but some timblocks have more transactions than others)\n",
    "# - Devide to total transactions per timeblock (proportions)\n",
    "# - Use both\n",
    "# - Use only proportions\n",
    "train_df, test_df = timeblock_frequency_encoding(train_df, test_df, periods, i_cols, \n",
    "                                 with_proportions=False, only_proportions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### D Columns\n",
    "# From columns description we know that\n",
    "# D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "# 1. I can't imagine normal negative timedelta values (Let's clip Values)\n",
    "# 2. Normalize (Min-Max, Standard score) All D columns, except D1,D2,D9\n",
    "# 3. Do some aggregations based on uIDs\n",
    "# 4. Freaquency encoding\n",
    "# 5. D1,D2 are clipped by max train_df values (let's scale it)\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "uids = ['uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "####### uIDs aggregations\n",
    "train_df, test_df = uid_aggregation(train_df, test_df, i_cols, uids, aggregations)\n",
    "\n",
    "####### Cleaning Neagtive values and columns transformations\n",
    "for df in [train_df, test_df]:\n",
    "\n",
    "    for col in i_cols:\n",
    "        df[col] = df[col].clip(0) \n",
    "    \n",
    "    # Lets transform D8 and D9 column\n",
    "    # As we almost sure it has connection with hours\n",
    "    df['D9_not_na'] = np.where(df['D9'].isna(),0,1)\n",
    "    df['D8_not_same_day'] = np.where(df['D8']>=1,1,0)\n",
    "    df['D8_D9_decimal_dist'] = df['D8'].fillna(0)-df['D8'].fillna(0).astype(int)\n",
    "    df['D8_D9_decimal_dist'] = ((df['D8_D9_decimal_dist']-df['D9'])**2)**0.5\n",
    "    df['D8'] = df['D8'].fillna(-1).astype(int)\n",
    "\n",
    "####### Values Normalization\n",
    "i_cols.remove('D1')\n",
    "i_cols.remove('D2')\n",
    "i_cols.remove('D9')\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [train_df, test_df]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "for col in ['D1','D2']:\n",
    "    for df in [train_df, test_df]:\n",
    "        df[col+'_scaled'] = df[col]/train_df[col].max()\n",
    "        \n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAADdCAYAAAD3nuA9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13dfbf750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### TransactionAmt\n",
    "i_cols = ['TransactionAmt']\n",
    "periods = ['DT_D']\n",
    "\n",
    "temp_df = pd.concat([train_df[['TransactionDT']+i_cols+periods], test_df[['TransactionDT']+i_cols+periods]])\n",
    "for period in periods:\n",
    "    for col in i_cols:\n",
    "        for df in [temp_df]:\n",
    "            df.set_index(period)[col].plot(style='.', title=col, figsize=(15, 3))\n",
    "            plt.show()\n",
    "\n",
    "# Clip Values\n",
    "train_df['TransactionAmt'] = train_df['TransactionAmt'].clip(0,5000)\n",
    "test_df['TransactionAmt']  = test_df['TransactionAmt'].clip(0,5000)\n",
    "\n",
    "# Check if the Transaction Amount is common or not (we can use freq encoding here)\n",
    "# In our dialog with a model we are telling to trust or not to these values   \n",
    "train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
    "test_df['TransactionAmt_check']  = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
    "\n",
    "# For our model current TransactionAmt is a noise\n",
    "# https://www.kaggle.com/kyakovlev/ieee-check-noise\n",
    "# (even if features importances are telling contrariwise)\n",
    "# There are many unique values and model doesn't generalize well\n",
    "# Lets do some aggregations\n",
    "i_cols = ['TransactionAmt']\n",
    "uids = ['card1','card2','card3','card5','uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "# uIDs aggregations\n",
    "train_df, test_df = uid_aggregation(train_df, test_df, i_cols, uids, aggregations)\n",
    " \n",
    "# TransactionAmt Normalization\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [train_df, test_df]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "# Product type\n",
    "train_df['product_type'] = train_df['ProductCD'].astype(str)+'_'+train_df['TransactionAmt'].astype(str)\n",
    "test_df['product_type'] = test_df['ProductCD'].astype(str)+'_'+test_df['TransactionAmt'].astype(str)\n",
    "\n",
    "i_cols = ['product_type']\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "train_df, test_df = timeblock_frequency_encoding(train_df, test_df, periods, i_cols, \n",
    "                                                 with_proportions=False, only_proportions=True)\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)\n",
    "\n",
    "# Small \"hack\" to transform distribution \n",
    "# (doesn't affect auc much, but I like it more)\n",
    "# please see how distribution transformation can boost your score \n",
    "# (not our case but related)\n",
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html\n",
    "train_df['TransactionAmt'] = np.log1p(train_df['TransactionAmt'])\n",
    "test_df['TransactionAmt'] = np.log1p(test_df['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### C Columns\n",
    "i_cols = ['C'+str(i) for i in range(1,15)]\n",
    "\n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=False because \n",
    "# I want to keep original values\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=False)\n",
    "\n",
    "####### Clip max values\n",
    "for df in [train_df, test_df]:\n",
    "    for col in i_cols:\n",
    "        max_value = train_df[train_df['DT_M']==train_df['DT_M'].max()][col].max()\n",
    "        df[col] = df[col].clip(None,max_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Device info and identity\n",
    "for df in [train_identity, test_identity]:\n",
    "    ########################### Device info\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "    df['DeviceInfo_device'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['DeviceInfo_version'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if unicode(i).isnumeric()]))\n",
    "    \n",
    "    ########################### Device info 2\n",
    "    df['id_30'] = df['id_30'].fillna('unknown_device').str.lower()\n",
    "    df['id_30_device'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['id_30_version'] = df['id_30'].apply(lambda x: ''.join([i for i in x if unicode(i).isnumeric()]))\n",
    "    \n",
    "    ########################### Browser\n",
    "    df['id_31'] = df['id_31'].fillna('unknown_device').str.lower()\n",
    "    df['id_31_device'] = df['id_31'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    \n",
    "########################### Merge Identity columns\n",
    "temp_df = train_df[['TransactionID']]\n",
    "temp_df = temp_df.merge(train_identity, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "train_df = pd.concat([train_df,temp_df], axis=1)\n",
    "    \n",
    "temp_df = test_df[['TransactionID']]\n",
    "temp_df = temp_df.merge(test_identity, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "test_df = pd.concat([test_df,temp_df], axis=1)\n",
    "\n",
    "i_cols = [\n",
    "          'DeviceInfo','DeviceInfo_device','DeviceInfo_version',\n",
    "          'id_30','id_30_device','id_30_version',\n",
    "          'id_31','id_31_device',\n",
    "          'id_33',\n",
    "         ]\n",
    "\n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### ProductCD and M4 Target mean\n",
    "# As we already have frequency encoded columns\n",
    "# We can have different global transformation on them\n",
    "# Target mean?\n",
    "# We will transform original values as we don't need them\n",
    "# Leakage over folds?\n",
    "# Yes, we will have some,\n",
    "# But in the same time we already have leakage from \n",
    "# V columns and card1->card6 columns\n",
    "# So, no much harm here\n",
    "for col in ['ProductCD','M4']:\n",
    "    temp_dict = train_df.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    train_df[col] = train_df[col].map(temp_dict)\n",
    "    test_df[col]  = test_df[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_emaildomain\n",
      "R_emaildomain\n",
      "uid\n",
      "uid2\n",
      "uid3\n",
      "uid4\n",
      "uid5\n",
      "bank_type\n",
      "DeviceType\n"
     ]
    }
   ],
   "source": [
    "########################### Encode Str columns\n",
    "# For all such columns (probably not)\n",
    "# we already did frequency encoding (numeric feature)\n",
    "# so we will use astype('category') here\n",
    "for col in list(train_df):\n",
    "    if train_df[col].dtype=='O':\n",
    "        print(col)\n",
    "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
    "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col])+list(test_df[col]))\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col]  = le.transform(test_df[col])\n",
    "        \n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Minification\n",
    "remove_features = pd.DataFrame(remove_features, columns=['features_to_remove'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 791)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 791)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df98.csv',index=False)\n",
    "test_df.to_csv('test_df98.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features.to_csv('remove_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
