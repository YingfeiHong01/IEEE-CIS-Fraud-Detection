{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False\n",
    "TARGET = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "train_transaction = pd.read_csv('train_transaction.csv')\n",
    "test_identity = pd.read_csv('test_identity.csv')\n",
    "test_transaction = pd.read_csv('test_transaction.csv')\n",
    "# let's combine the data and work with the whole dataset\n",
    "train_df = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test_df = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\n",
    "del train_identity, train_transaction, test_identity,test_transaction \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_card = train_df['card1'].value_counts()\n",
    "valid_card = valid_card[valid_card>10]\n",
    "valid_card = list(valid_card.index)\n",
    "    \n",
    "train_df['card1'] = np.where(train_df['card1'].isin(valid_card), train_df['card1'], np.nan)\n",
    "test_df['card1']  = np.where(test_df['card1'].isin(valid_card), test_df['card1'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['card1','card2','card3','card5',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'D1','D2','D3','D4','D5','D6','D7','D8','D9',\n",
    "          'addr1','addr2',\n",
    "          'dist1','dist2',\n",
    "          'P_emaildomain', 'R_emaildomain'\n",
    "         ]\n",
    "\n",
    "for col in i_cols:\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()   \n",
    "    train_df[col+'_fq_enc'] = train_df[col].map(fq_encode)\n",
    "    test_df[col+'_fq_enc']  = test_df[col].map(fq_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['ProductCD','M4']:\n",
    "    temp_dict = train_df.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    train_df[col+'_target_mean'] = train_df[col].map(temp_dict)\n",
    "    test_df[col+'_target_mean']  = test_df[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD\n",
      "card4\n",
      "card6\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "M7\n",
      "M8\n",
      "M9\n",
      "id_12\n",
      "id_15\n",
      "id_16\n",
      "id_23\n",
      "id_27\n",
      "id_28\n",
      "id_29\n",
      "id_30\n",
      "id_31\n",
      "id_33\n",
      "id_34\n",
      "id_35\n",
      "id_36\n",
      "id_37\n",
      "id_38\n",
      "DeviceType\n",
      "DeviceInfo\n"
     ]
    }
   ],
   "source": [
    "for col in list(train_df):\n",
    "    if train_df[col].dtype=='O':\n",
    "        print(col)\n",
    "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
    "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col])+list(test_df[col]))\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col]  = le.transform(test_df[col])\n",
    "        \n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Transaction Amount is common or not (we can use freq encoding here)\n",
    "# In our dialog with model we are telling to trust or not to these values  \n",
    "valid_card = train_df['TransactionAmt'].value_counts()\n",
    "valid_card = valid_card[valid_card>10]\n",
    "valid_card = list(valid_card.index)\n",
    "    \n",
    "train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
    "test_df['TransactionAmt_check']  = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
    "\n",
    "# For our model current TransactionAmt is a noise (even features importances are telling contrariwise)\n",
    "# There are many unique values and model doesn't generalize well\n",
    "# Lets do some aggregations\n",
    "i_cols = ['card1','card2','card3','card5']\n",
    "\n",
    "for col in i_cols:\n",
    "    for agg_type in ['mean', 'std']:\n",
    "        new_col_name = col+'_TransactionAmt_'+agg_type\n",
    "        temp_df = pd.concat([train_df[[col, 'TransactionAmt']], test_df[[col,'TransactionAmt']]])\n",
    "        temp_df = temp_df.groupby([col])['TransactionAmt'].agg([agg_type]).reset_index().rename(\n",
    "                                                columns={agg_type: new_col_name})\n",
    "        \n",
    "        temp_df.index = list(temp_df[col])\n",
    "        temp_df = temp_df[new_col_name].to_dict()   \n",
    "    \n",
    "        train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "        test_df[new_col_name]  = test_df[col].map(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_more.csv',index=False)\n",
    "test_df.to_csv('test_more.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
